{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"180303_keras_psuedo.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"1pyCto6soNmr","colab_type":"text"},"cell_type":"markdown","source":["# Statoil/C-CORE Iceberg Classifier Challenge\n","\n","Link: https://www.kaggle.com/c/statoil-iceberg-classifier-challenge\n"]},{"metadata":{"id":"yEfpEqb3oNmu","colab_type":"text"},"cell_type":"markdown","source":["This Kernal implements a Keras + Tensorflow CNN for the StatOil Iceberg competition. It has yielded results of 0.1995 on the leaderboard. With some tuning and image filtering plus more of an inclusion of the incident angle, a better result could be yielded I'm sure.\n","\n","The input is a 75x75x3 set of images. The output is a binary 0/1 where 1 is noteed as an iceberg. \n","\n","The set of images are band_1 (HH), band_2 (HV), and an combined band which would be (HH dot HV)/constant. However, since we are working with the images in dB, the 3rd band is modified to compenate for the log function yielding band_1 + band_2 -log(constant). The last term is neglected as when the images are scaled the 3rd term would be removed by the mathematics anyway.\n","\n","This and other information can be found from: https://earth.esa.int/c/document_library/get_file?folderId=409229&name=DLFE-5566.pdf"]},{"metadata":{"id":"a9Q9ala1oNmw","colab_type":"text"},"cell_type":"markdown","source":["## 1. Imports packages"]},{"metadata":{"id":"c25GjCtSswTB","colab_type":"text"},"cell_type":"markdown","source":["How to use GPU on google drive: https://zhuanlan.zhihu.com/p/33344222"]},{"metadata":{"id":"J_vccNSSqmjW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ei0O6Sspo7_I","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":170},"outputId":"6feba7a3-7522-4548-916b-a2bcdf300580","executionInfo":{"status":"ok","timestamp":1520295113708,"user_tz":300,"elapsed":7135,"user":{"displayName":"Jian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100035481140881803216"}}},"cell_type":"code","source":["# https://opencv.org/\n","!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n","!pip install keras\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting keras\n","  Downloading Keras-2.1.4-py2.py3-none-any.whl (322kB)\n","\u001b[K    100% |████████████████████████████████| 327kB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras)\n","Installing collected packages: keras\n","Successfully installed keras-2.1.4\n"],"name":"stdout"}]},{"metadata":{"id":"8YY4oa04oNmz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd \n","import numpy as np \n","import cv2 # Used to manipulated the images \n","np.random.seed(1337) # Set the seed to generate same random sequence\n","\n","# Import Keras \n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.layers.normalization import BatchNormalization\n","import keras.backend as K\n","from keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t3T5riqUoNm7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def limit_men():\n","    cfg = K.tf.ConfigProto()\n","    cfg.gpu_options.allow_growth = True\n","    K.set_session(K.tf.Session(config=cfg))\n","limit_men()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_YUPC36YoNnD","colab_type":"text"},"cell_type":"markdown","source":["## 2.Data engineering"]},{"metadata":{"id":"GyPWJlgmoNnE","colab_type":"text"},"cell_type":"markdown","source":["### 2.1 Load Training Data\n"]},{"metadata":{"id":"069ZAhzqoNnG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1},{"item_id":2}],"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":218},"outputId":"8c14bd2c-cc5e-4cb8-f2a2-84bc4c5da151","executionInfo":{"status":"error","timestamp":1520297863905,"user_tz":300,"elapsed":18483,"user":{"displayName":"Jian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100035481140881803216"}}},"cell_type":"code","source":["import io\n","from google.colab import files\n","uploaded = files.upload()\n","df_train = pd.read_json(io.StringIO(uploaded['train.json'].decode('utf-8')))"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-28742c70-6603-4870-ad07-e9ca095bde28\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-28742c70-6603-4870-ad07-e9ca095bde28\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-8c1bd0e1755c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train.json'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 'train.json'"]}]},{"metadata":{"id":"5-0xhVpXoNnL","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://)The database contains 1604 data sample and five features: band 1, band 2 , id , inc angle, is iceberg\n"]},{"metadata":{"id":"RLkyVUl_oNnO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"0946f383-4b19-4149-9ffb-da56ffec4b28"},"cell_type":"code","source":["print ( \"The shape of database is :\", df_train.shape) \n","print( \"Show the first three examples\")\n","df_train[:3]\n","print(\"How many pixels in the each chart\",len(df_train[\"band_1\"][0]), \n","      \"which is equalt to 75*75\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The shape of database is : (1604, 5)\n","Show the first three examples\n","How many pixels in the each chart 5625 which is equalt to 75*75\n"],"name":"stdout"}]},{"metadata":{"id":"INRidYqNoNnZ","colab_type":"text"},"cell_type":"markdown","source":["Need to reshape and feature scale the images: reshape the chart into [75 * 75] and scale each pixel with max- min"]},{"metadata":{"id":"lQognNmIoNnb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_scaled_imgs(df):\n","    imgs = []\n","    \n","    for i, row in df.iterrows():\n","        #make 75x75 image\n","        band_1 = np.array(row['band_1']).reshape(75, 75)\n","        band_2 = np.array(row['band_2']).reshape(75, 75)\n","        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n","        \n","        # Rescale\n","        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n","        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n","        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n","\n","        imgs.append(np.dstack((a, b, c)))\n","\n","    return np.array(imgs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JsHjlSdmoNng","colab_type":"text"},"cell_type":"markdown","source":["Get the train data"]},{"metadata":{"id":"_y4PgO8IoNni","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"89b3b925-e99a-4a20-f9cc-f00bcd0f424d"},"cell_type":"code","source":["Xtrain_orig = get_scaled_imgs(df_train)\n","print( \"The shape after reshape is:\", Xtrain_orig.shape, \n","      \" The three dimension is band 1, band 2 and (band 1+ band 2)/2\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The shape after reshape is: (1604, 75, 75, 3)  The three dimension is band 1, band 2 and (band 1+ band 2)/2\n"],"name":"stdout"}]},{"metadata":{"id":"oSIl8FG3oNno","colab_type":"text"},"cell_type":"markdown","source":["Get the response variable \"is_iceberg\": to verify if the chart contains ice_berg"]},{"metadata":{"id":"URm2KS7moNnq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Ytrain_orig = np.array(df_train['is_iceberg'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1ymagdq7oNnu","colab_type":"text"},"cell_type":"markdown","source":["Deal with the missing value: Some of the incident angle from the satellite are unknown and marked as \"na\". Replace these na with 0 and find the indices where the incident angle is >0 (this way you can use a truncated set or the full set of training data). negelect all the \"na\" data in the data sample"]},{"metadata":{"id":"2WKhfetLoNnv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["df_train.inc_angle = df_train.inc_angle.replace('na',0)\n","idx_tr = np.where(df_train.inc_angle>0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jx3_QVJeoNn0","colab_type":"text"},"cell_type":"markdown","source":["You can now use the option of training with only known incident angles or the whole set. I found slightly better results training with only the known incident angles so:"]},{"metadata":{"id":"rUhniIo1oNn1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"f4c49269-ff59-438e-ed65-ca3b1f225b73"},"cell_type":"code","source":["Ytrain = Ytrain_orig[idx_tr[0]]\n","Xtrain = Xtrain_orig[idx_tr[0],...]\n","print(\"The remaining shape after dealing with missing value is :\", Xtrain.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The remaining shape after dealing with missing value is : (1471, 75, 75, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"WhmQ5TJ9oNn7","colab_type":"text"},"cell_type":"markdown","source":["### 2.2 Adding images for training"]},{"metadata":{"id":"vz9UML1VoNn9","colab_type":"text"},"cell_type":"markdown","source":["Now, the biggest improvement I had was by adding more data to train on. I did this by simply including horizontally and vertically flipped data. Using OpenCV this is easily done. The final data will contain original chart, vertical chart  and horizontal chart\n","\n","link:https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#void \n","\n","Parameters:\t\n","src – input array.\n","\n","dst – output array of the same size and type as src.\n","flipCode – a flag to specify how to flip the array; 0 means flipping around the x-axis and positive value (for example, 1) means flipping around y-axis. Negative value (for example, -1) means flipping around both axes (see the discussion below for the formulas)."]},{"metadata":{"id":"CiInXh8ZoNn-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_more_images(imgs):\n","    \n","    more_images = []\n","    vert_flip_imgs = []\n","    hori_flip_imgs = []\n","      \n","    for i in range(0,imgs.shape[0]):\n","        a=imgs[i,:,:,0]\n","        b=imgs[i,:,:,1]\n","        c=imgs[i,:,:,2]\n","        \n","        # vertical rotate\n","        av=cv2.flip(a,1)\n","        # horizontal rotate\n","        ah=cv2.flip(a,0)\n","        bv=cv2.flip(b,1)\n","        bh=cv2.flip(b,0)\n","        cv=cv2.flip(c,1)\n","        ch=cv2.flip(c,0)\n","        \n","        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n","        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n","      \n","    v = np.array(vert_flip_imgs)\n","    h = np.array(hori_flip_imgs)\n","       \n","    more_images = np.concatenate((imgs,v,h))\n","    \n","    return more_images\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EJo_q_fqoNoF","colab_type":"text"},"cell_type":"markdown","source":["I rename the returned value so i have the option of using the original data set or the expanded data set"]},{"metadata":{"id":"CzNVTEjmoNoG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Xtr_more = get_more_images(Xtrain) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"y9gE8kZQoNoK","colab_type":"text"},"cell_type":"markdown","source":["And then define the new response variable: response is just the three times of the original data, since the chart rotation will not influnce the results of responses"]},{"metadata":{"id":"ouC2UMaVoNoL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Ytr_more = np.concatenate((Ytrain,Ytrain,Ytrain))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pNtIUoIHoNoU","colab_type":"text"},"cell_type":"markdown","source":["## 3. CNN Keras Model"]},{"metadata":{"id":"gWkqwk-BoNoV","colab_type":"text"},"cell_type":"markdown","source":["Convolutional neural networks (CNNs) are the current state-of-the-art model architecture for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains three components:\n","\n","**Convolutional layers**, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.\n","\n","**Pooling layers**, which downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.\n","\n","**Dense (fully connected) layers**, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n","\n","Example of a CNN:\n","\n","<img src=\"../images/cnn.png\" />"]},{"metadata":{"id":"Vh6IEs1roNoW","colab_type":"text"},"cell_type":"markdown","source":["Now the nitty gritty of the situation, the CNN model. The model contains 4 cnn layers and 2 dense layers.\n","\n","The link about sequential model:https://keras.io/getting-started/sequential-model-guide/\n","\n","Link of convolutional layers: https://keras.io/layers/convolutional/\n","\n","Standford convulutinal neural network link:http://cs231n.github.io/convolutional-networks/\n","\n","Default filters glorot uniform: https://keras.io/initializers/\n","\n","Optimization function: http://ruder.io/optimizing-gradient-descent/index.html#adam\n","\n","Activation function :https://en.wikipedia.org/wiki/Activation_function\n","\n","Some important parameters:\n","\n","filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n","\n","kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n","\n","strides: An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any  dilation_rate value != 1.\n","\n","padding: One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. Useful when modeling temporal data where the model should not violate the temporal order. See WaveNet: A Generative Model for Raw Audio, section 2.1.\n","\n","dilation_rate: an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any strides value != 1.\n","\n","activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n","\n","\n","\n"]},{"metadata":{"id":"gPt8ivI7oNoX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def getModel():\n","    #Build keras model\n","    \n","    model=Sequential()\n","    \n","    # CNN 1\n","    model.add(Conv2D(filtes=64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n","    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    # CNN 2\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    # CNN 3\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    #CNN 4\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    # You must flatten the data for the dense layers: nakes it one dimension\n","    model.add(Flatten())\n","\n","    #Dense 1\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    #Dense 2\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    # Output \n","    model.add(Dense(1, activation=\"sigmoid\"))\n","\n","    optimizer = Adam(lr=0.001, decay=0.0)\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1H-5puD4oNoc","colab_type":"text"},"cell_type":"markdown","source":["Now get the model and get ready to train"]},{"metadata":{"id":"r02sZvsjoNod","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"ac534bba-6052-4e36-a66c-b3fb86670d79"},"cell_type":"code","source":["model = getModel()\n","model.summary()\n","\n","batch_size = 32\n","earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n","mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n","reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, \n","                                   epsilon=1e-4, mode='min')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 73, 73, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 36, 36, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 5, 5, 64)          73792     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 64)          0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 2, 2, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 560,193\n","Trainable params: 560,193\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"-p2K7eswoNoh","colab_type":"text"},"cell_type":"markdown","source":["Now train the model! (Each epoch ran at about 10s on GPU)"]},{"metadata":{"id":"aioB3yiboNoi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"outputId":"104689e2-ade2-41aa-83fe-916a92ac895c"},"cell_type":"code","source":["model.fit(Xtr_more, Ytr_more, batch_size=batch_size, epochs=50, verbose=1, \n","          callbacks=[mcp_save, reduce_lr_loss], validation_split=0.25)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 3309 samples, validate on 1104 samples\n","Epoch 1/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.5589 - acc: 0.7014 - val_loss: 0.4020 - val_acc: 0.8288\n","Epoch 2/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.4087 - acc: 0.8154 - val_loss: 0.5990 - val_acc: 0.7120\n","Epoch 3/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.3281 - acc: 0.8516 - val_loss: 0.3425 - val_acc: 0.8433\n","Epoch 4/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.2746 - acc: 0.8803 - val_loss: 0.2508 - val_acc: 0.9004\n","Epoch 5/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.2522 - acc: 0.8921 - val_loss: 0.3039 - val_acc: 0.8668\n","Epoch 6/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.2273 - acc: 0.9036 - val_loss: 0.2306 - val_acc: 0.9139\n","Epoch 7/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.2077 - acc: 0.9102 - val_loss: 0.2291 - val_acc: 0.9212\n","Epoch 8/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.1899 - acc: 0.9211 - val_loss: 0.2280 - val_acc: 0.9085\n","Epoch 9/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.1941 - acc: 0.9226 - val_loss: 0.2136 - val_acc: 0.9194\n","Epoch 10/50\n","3309/3309 [==============================] - 45s 13ms/step - loss: 0.1776 - acc: 0.9332 - val_loss: 0.2150 - val_acc: 0.9139\n","Epoch 11/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1550 - acc: 0.9368 - val_loss: 0.2087 - val_acc: 0.9257\n","Epoch 12/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1504 - acc: 0.9414 - val_loss: 0.2200 - val_acc: 0.9121\n","Epoch 13/50\n","3309/3309 [==============================] - 47s 14ms/step - loss: 0.1465 - acc: 0.9405 - val_loss: 0.2255 - val_acc: 0.9040\n","Epoch 14/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1176 - acc: 0.9538 - val_loss: 0.2578 - val_acc: 0.9094\n","Epoch 15/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1210 - acc: 0.9589 - val_loss: 0.2319 - val_acc: 0.9194\n","Epoch 16/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1130 - acc: 0.9592 - val_loss: 0.2240 - val_acc: 0.9176\n","Epoch 17/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.1047 - acc: 0.9580 - val_loss: 0.2090 - val_acc: 0.9203\n","Epoch 18/50\n","3309/3309 [==============================] - 45s 13ms/step - loss: 0.0954 - acc: 0.9655 - val_loss: 0.2758 - val_acc: 0.8832\n","Epoch 19/50\n","3296/3309 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9697\n","Epoch 00019: reducing learning rate to 0.00010000000474974513.\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0808 - acc: 0.9695 - val_loss: 0.2136 - val_acc: 0.9275\n","Epoch 20/50\n","3309/3309 [==============================] - 47s 14ms/step - loss: 0.0532 - acc: 0.9813 - val_loss: 0.2235 - val_acc: 0.9257\n","Epoch 21/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0353 - acc: 0.9885 - val_loss: 0.2466 - val_acc: 0.9266\n","Epoch 22/50\n","3309/3309 [==============================] - 45s 13ms/step - loss: 0.0317 - acc: 0.9885 - val_loss: 0.2548 - val_acc: 0.9257\n","Epoch 23/50\n","3309/3309 [==============================] - 45s 13ms/step - loss: 0.0344 - acc: 0.9855 - val_loss: 0.2939 - val_acc: 0.9248\n","Epoch 24/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0300 - acc: 0.9876 - val_loss: 0.2775 - val_acc: 0.9221\n","Epoch 25/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0260 - acc: 0.9909 - val_loss: 0.2963 - val_acc: 0.9221\n","Epoch 26/50\n","3296/3309 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9900\n","Epoch 00026: reducing learning rate to 1.0000000474974514e-05.\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0279 - acc: 0.9900 - val_loss: 0.2939 - val_acc: 0.9203\n","Epoch 27/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0210 - acc: 0.9924 - val_loss: 0.2982 - val_acc: 0.9212\n","Epoch 28/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0210 - acc: 0.9915 - val_loss: 0.2910 - val_acc: 0.9248\n","Epoch 29/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0195 - acc: 0.9912 - val_loss: 0.2948 - val_acc: 0.9221\n","Epoch 30/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0193 - acc: 0.9927 - val_loss: 0.2914 - val_acc: 0.9230\n","Epoch 31/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.2945 - val_acc: 0.9221\n","Epoch 32/50\n","3309/3309 [==============================] - 45s 13ms/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.2937 - val_acc: 0.9203\n","Epoch 33/50\n","3296/3309 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9909\n","Epoch 00033: reducing learning rate to 1.0000000656873453e-06.\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0232 - acc: 0.9909 - val_loss: 0.2926 - val_acc: 0.9239\n","Epoch 34/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.2932 - val_acc: 0.9239\n","Epoch 35/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0211 - acc: 0.9915 - val_loss: 0.2937 - val_acc: 0.9230\n","Epoch 36/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0171 - acc: 0.9955 - val_loss: 0.2939 - val_acc: 0.9230\n","Epoch 37/50\n","3309/3309 [==============================] - 44s 13ms/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.2942 - val_acc: 0.9212\n","Epoch 38/50\n","3309/3309 [==============================] - 47s 14ms/step - loss: 0.0183 - acc: 0.9940 - val_loss: 0.2942 - val_acc: 0.9212\n","Epoch 39/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0218 - acc: 0.9918 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 40/50\n","3296/3309 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9945\n","Epoch 00040: reducing learning rate to 1.0000001111620805e-07.\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.2946 - val_acc: 0.9203\n","Epoch 41/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0196 - acc: 0.9930 - val_loss: 0.2946 - val_acc: 0.9203\n","Epoch 42/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 43/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0200 - acc: 0.9930 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 44/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0205 - acc: 0.9924 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 45/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0168 - acc: 0.9930 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 46/50\n","3309/3309 [==============================] - 45s 14ms/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 47/50\n","3296/3309 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9921\n","Epoch 00047: reducing learning rate to 1.000000082740371e-08.\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0187 - acc: 0.9921 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 48/50\n","3309/3309 [==============================] - 48s 14ms/step - loss: 0.0211 - acc: 0.9934 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 49/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0156 - acc: 0.9952 - val_loss: 0.2947 - val_acc: 0.9203\n","Epoch 50/50\n","3309/3309 [==============================] - 46s 14ms/step - loss: 0.0227 - acc: 0.9918 - val_loss: 0.2947 - val_acc: 0.9203\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe79dff1550>"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"-duWK3yjoNom","colab_type":"text"},"cell_type":"markdown","source":["## Results"]},{"metadata":{"id":"fqRo3dc_oNoo","colab_type":"text"},"cell_type":"markdown","source":["Load the best weights and check the score on the training data."]},{"metadata":{"id":"KxEKCkogoNop","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"799bfd3e-ff82-4ce7-850f-41f17567c26b"},"cell_type":"code","source":["model.load_weights(filepath = '.mdl_wts.hdf5')\n","\n","score = model.evaluate(Xtrain, Ytrain, verbose=1)\n","print('Train score:', score[0])\n","print('Train accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1471/1471 [==============================] - 5s 4ms/step\n","Train score: 0.104133588701\n","Train accuracy: 0.963970087767\n"],"name":"stdout"}]},{"metadata":{"id":"7yyBCayfoNou","colab_type":"text"},"cell_type":"markdown","source":["## Psuedo labelling \n","\n","Use the model to predict the test data and use the result as label to retrain the train+test data. Use the retrained model with psuedo labeling data to predict the test sample. First predict the classes for the test data."]},{"metadata":{"id":"6j4o469FoNov","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"edbca81d-1173-45f8-924a-ac7514d80c25"},"cell_type":"code","source":["df_test = pd.read_json('../data/test.json')\n","df_test.inc_angle = df_test.inc_angle.replace('na',0)\n","Xtest = (get_scaled_imgs(df_test))\n","pred_test_classes = model.predict_classes(Xtest)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'get_scaled_imgs' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-11-8df224bd81b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minc_angle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minc_angle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'na'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mXtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_scaled_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpred_test_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'get_scaled_imgs' is not defined"]}]},{"metadata":{"id":"Cs4DghjloNoy","colab_type":"text"},"cell_type":"markdown","source":["Next retrain the model with psuedo labeling test data+ train data\n"]},{"metadata":{"id":"CbV-HOqRoNoz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"3fb1ac4d-b946-482b-82e2-d8ba0ae7c4cd"},"cell_type":"code","source":["x_train_total=np.concatenate((Xtest,Xtr_more),axis=0)\n","y_train_total=np.concatenate((Ytr_more[:,np.newaxis],pred_test_classes),axis =0)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"axis 1 out of bounds [0, 1)","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-27-d6bbced68cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_train_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtr_more\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYtr_more\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_test_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mIndexError\u001b[0m: axis 1 out of bounds [0, 1)"]}]},{"metadata":{"id":"y-GdUtq9oNo3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"f8b44c5f-495e-4852-e991-17c5e02862cd"},"cell_type":"code","source":["import time \n","tic=time.time()\n","model.fit(x_train_total, y_train_total, batch_size=batch_size, epochs=50, \n","          verbose=1, callbacks=[mcp_save, reduce_lr_loss], validation_split=0.25)\n","print(time.time()-tic)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 9627 samples, validate on 3210 samples\n","Epoch 1/50\n","9627/9627 [==============================] - 134s 14ms/step - loss: 2.4336 - acc: 0.5006 - val_loss: 3.2997 - val_acc: 0.4754\n","Epoch 2/50\n","9627/9627 [==============================] - 139s 14ms/step - loss: 2.4359 - acc: 0.4943 - val_loss: 3.2951 - val_acc: 0.4757\n","Epoch 3/50\n","9627/9627 [==============================] - 135s 14ms/step - loss: 2.4090 - acc: 0.4962 - val_loss: 3.2913 - val_acc: 0.4757\n","Epoch 4/50\n","9627/9627 [==============================] - 139s 14ms/step - loss: 2.4168 - acc: 0.4953 - val_loss: 3.2878 - val_acc: 0.4757\n","Epoch 5/50\n","9627/9627 [==============================] - 136s 14ms/step - loss: 2.4007 - acc: 0.4965 - val_loss: 3.2846 - val_acc: 0.4757\n","Epoch 6/50\n","9627/9627 [==============================] - 139s 14ms/step - loss: 2.4189 - acc: 0.4993 - val_loss: 3.2815 - val_acc: 0.4760\n","Epoch 7/50\n","9627/9627 [==============================] - 138s 14ms/step - loss: 2.4125 - acc: 0.4982 - val_loss: 3.2785 - val_acc: 0.4760\n","Epoch 8/50\n","9627/9627 [==============================] - 144s 15ms/step - loss: 2.3976 - acc: 0.4980 - val_loss: 3.2755 - val_acc: 0.4760\n","Epoch 9/50\n","9627/9627 [==============================] - 133s 14ms/step - loss: 2.4151 - acc: 0.4926 - val_loss: 3.2726 - val_acc: 0.4760\n","Epoch 10/50\n","9627/9627 [==============================] - 137s 14ms/step - loss: 2.3836 - acc: 0.4970 - val_loss: 3.2697 - val_acc: 0.4760\n","Epoch 11/50\n","9627/9627 [==============================] - 144s 15ms/step - loss: 2.3974 - acc: 0.4982 - val_loss: 3.2669 - val_acc: 0.4760\n","Epoch 12/50\n","9627/9627 [==============================] - 140s 15ms/step - loss: 2.4191 - acc: 0.4938 - val_loss: 3.2641 - val_acc: 0.4760\n","Epoch 13/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.4122 - acc: 0.4976 - val_loss: 3.2612 - val_acc: 0.4760\n","Epoch 14/50\n","9627/9627 [==============================] - 142s 15ms/step - loss: 2.4054 - acc: 0.4951 - val_loss: 3.2584 - val_acc: 0.4760\n","Epoch 15/50\n","9627/9627 [==============================] - 140s 15ms/step - loss: 2.4053 - acc: 0.4926 - val_loss: 3.2555 - val_acc: 0.4760\n","Epoch 16/50\n","9627/9627 [==============================] - 138s 14ms/step - loss: 2.3887 - acc: 0.4957 - val_loss: 3.2527 - val_acc: 0.4760\n","Epoch 17/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.4009 - acc: 0.4936 - val_loss: 3.2499 - val_acc: 0.4760\n","Epoch 18/50\n","9627/9627 [==============================] - 140s 15ms/step - loss: 2.4046 - acc: 0.4910 - val_loss: 3.2470 - val_acc: 0.4757\n","Epoch 19/50\n","9627/9627 [==============================] - 138s 14ms/step - loss: 2.3835 - acc: 0.4958 - val_loss: 3.2443 - val_acc: 0.4757\n","Epoch 20/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.3992 - acc: 0.4933 - val_loss: 3.2415 - val_acc: 0.4757\n","Epoch 21/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.3763 - acc: 0.4949 - val_loss: 3.2387 - val_acc: 0.4757\n","Epoch 22/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.3879 - acc: 0.4961 - val_loss: 3.2359 - val_acc: 0.4757\n","Epoch 23/50\n","9627/9627 [==============================] - 141s 15ms/step - loss: 2.3936 - acc: 0.4926 - val_loss: 3.2331 - val_acc: 0.4757\n","Epoch 24/50\n","9627/9627 [==============================] - 132s 14ms/step - loss: 2.3541 - acc: 0.4998 - val_loss: 3.2303 - val_acc: 0.4757\n","Epoch 25/50\n","9627/9627 [==============================] - 135s 14ms/step - loss: 2.3864 - acc: 0.4950 - val_loss: 3.2275 - val_acc: 0.4757\n","Epoch 26/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3682 - acc: 0.4986 - val_loss: 3.2247 - val_acc: 0.4757\n","Epoch 27/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3778 - acc: 0.4926 - val_loss: 3.2219 - val_acc: 0.4757\n","Epoch 28/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3598 - acc: 0.4948 - val_loss: 3.2191 - val_acc: 0.4757\n","Epoch 29/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3812 - acc: 0.4942 - val_loss: 3.2163 - val_acc: 0.4754\n","Epoch 30/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3686 - acc: 0.4990 - val_loss: 3.2135 - val_acc: 0.4754\n","Epoch 31/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3707 - acc: 0.4969 - val_loss: 3.2107 - val_acc: 0.4754\n","Epoch 32/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3774 - acc: 0.4953 - val_loss: 3.2079 - val_acc: 0.4757\n","Epoch 33/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3740 - acc: 0.4926 - val_loss: 3.2051 - val_acc: 0.4754\n","Epoch 34/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3686 - acc: 0.5022 - val_loss: 3.2023 - val_acc: 0.4754\n","Epoch 35/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3502 - acc: 0.4959 - val_loss: 3.1996 - val_acc: 0.4754\n","Epoch 36/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3542 - acc: 0.4938 - val_loss: 3.1967 - val_acc: 0.4757\n","Epoch 37/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3561 - acc: 0.4988 - val_loss: 3.1940 - val_acc: 0.4757\n","Epoch 38/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3630 - acc: 0.4938 - val_loss: 3.1912 - val_acc: 0.4757\n","Epoch 39/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3522 - acc: 0.4972 - val_loss: 3.1884 - val_acc: 0.4757\n","Epoch 40/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3362 - acc: 0.4987 - val_loss: 3.1857 - val_acc: 0.4757\n","Epoch 41/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3628 - acc: 0.4934 - val_loss: 3.1828 - val_acc: 0.4757\n","Epoch 42/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3433 - acc: 0.4982 - val_loss: 3.1800 - val_acc: 0.4757\n","Epoch 43/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3433 - acc: 0.4964 - val_loss: 3.1773 - val_acc: 0.4757\n","Epoch 44/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3387 - acc: 0.4945 - val_loss: 3.1745 - val_acc: 0.4757\n","Epoch 45/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3322 - acc: 0.4974 - val_loss: 3.1717 - val_acc: 0.4760\n","Epoch 46/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3297 - acc: 0.4943 - val_loss: 3.1688 - val_acc: 0.4760\n","Epoch 47/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3310 - acc: 0.4926 - val_loss: 3.1661 - val_acc: 0.4757\n","Epoch 48/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3415 - acc: 0.4947 - val_loss: 3.1633 - val_acc: 0.4757\n","Epoch 49/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3206 - acc: 0.4961 - val_loss: 3.1605 - val_acc: 0.4757\n","Epoch 50/50\n","9627/9627 [==============================] - 131s 14ms/step - loss: 2.3364 - acc: 0.4950 - val_loss: 3.1577 - val_acc: 0.4757\n","6739.693185329437\n"],"name":"stdout"}]},{"metadata":{"id":"BW7XclZ3oNo7","colab_type":"text"},"cell_type":"markdown","source":["Use the new model to predict the test data, fisrt to see the train accuaracy and then the test result\n"]},{"metadata":{"id":"qxLky12_oNo8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"3c63b883-004c-4466-a4ee-b0607ac71cc8"},"cell_type":"code","source":["score = model.evaluate(x_train_total, y_train_total, verbose=1)\n","print('Train score:', score[0])\n","print('Train accuracy:', score[1])\n","\n","pred_test = model.predict(Xtest)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12837/12837 [==============================] - 49s 4ms/step\n","Train score: 2.44602600345\n","Train accuracy: 0.491859468726\n"],"name":"stdout"}]},{"metadata":{"id":"9lBaQqdsoNpB","colab_type":"text"},"cell_type":"markdown","source":["Now, to make a submission, load the test data and train the model and output a csv file."]},{"metadata":{"id":"ok4t8cTLoNpC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"68755bae-bae9-46a0-f3c0-28f1beb6434f"},"cell_type":"code","source":["submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test.reshape((pred_test.shape[0]))})\n","print(submission.head(10))\n","\n","submission.to_csv('submission.csv', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["         id  is_iceberg\n","0  5941774d    0.025917\n","1  4023181e    0.955667\n","2  b20200e4    0.028548\n","3  e7f018bb    0.999707\n","4  4371c8c3    0.923421\n","5  a8d9b1fd    0.748707\n","6  29e7727e    0.017642\n","7  92a51ffb    0.999460\n","8  c769ac97    0.000126\n","9  aee0547d    0.000007\n"],"name":"stdout"}]},{"metadata":{"id":"7lC96ph4oNpG","colab_type":"text"},"cell_type":"markdown","source":["The best submission with this I received was 0.1813 on the leaderboard. Have a go and see how well you can do!"]},{"metadata":{"id":"0vtu9IBMoNpH","colab_type":"text"},"cell_type":"markdown","source":["## Test data augument\n","Try to use more test data,  by means of flip, and test the diferent test data in diferent time, finally take a stack resulting of different test data set."]},{"metadata":{"id":"QFT6Y9oNoNpI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from PIL import Image\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","# for band 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gXGLaVGroNpM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_scaled_imgs(dict):\n","    imgs = []\n","    \n","    for i in range (len(dict[\"band_1\"])):\n","        #make 75x75 image\n","        band_1 = np.array(dict[\"band_1\"][i]).reshape(75, 75)\n","        band_2 = np.array(dict[\"band_2\"][i]).reshape(75, 75)\n","        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n","        \n","        # Rescale\n","        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n","        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n","        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n","\n","        imgs.append(np.dstack((a, b, c)))\n","\n","    return np.array(imgs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T5XdtevBoNpP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for 45 rotation\n","gin_45={}\n","gin_45[\"band_1\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_1']])\n","gin_45[\"band_1\"] = gin_45[\"band_1\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=45)\n","datagen.fit(gin_45[\"band_1\"])\n","gin_45[\"band_2\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_2']])\n","gin_45[\"band_2\"] = gin_45[\"band_2\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=45)\n","datagen.fit(gin_45[\"band_2\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KI-W_L4hoNpR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_x_45=get_scaled_imgs(gin_45)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NqtUw-JBoNpU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for 90 rotation\n","gin_90={}\n","gin_90[\"band_1\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_1']])\n","gin_90[\"band_1\"] = gin_90[\"band_1\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=90)\n","datagen.fit(gin_90[\"band_1\"])\n","gin_90[\"band_2\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_2']])\n","gin_90[\"band_2\"] = gin_90[\"band_2\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=90)\n","datagen.fit(gin_90[\"band_2\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KGTrwUO_oNpX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_x_90=get_scaled_imgs(gin_90)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_6ANomuboNpa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for 135 rotation\n","gin_135={}\n","gin_135[\"band_1\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_1']])\n","gin_135[\"band_1\"] = gin_135[\"band_1\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=135)\n","datagen.fit(gin_135[\"band_1\"])\n","gin_135[\"band_2\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_2']])\n","gin_135[\"band_2\"] = gin_135[\"band_2\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=135)\n","datagen.fit(gin_135[\"band_2\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C7ueISbzoNpc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_x_135=get_scaled_imgs(gin_135)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"al1gkpYWoNpf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for 135 rotation\n","gin_180={}\n","gin_180[\"band_1\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_1']])\n","gin_180[\"band_1\"] = gin_180[\"band_1\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=135)\n","datagen.fit(gin_180[\"band_1\"])\n","gin_180[\"band_2\"] = np.asarray([np.asarray(p).reshape(75,75) for p in df_test['band_2']])\n","gin_180[\"band_2\"] = gin_180[\"band_2\"].reshape(8424,75,75,1)\n","datagen = ImageDataGenerator(rotation_range=135)\n","datagen.fit(gin_180[\"band_2\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n6mXsmyooNpj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_x_180=get_scaled_imgs(gin_180)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gd2kqOHWoNpm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"collapsed":true,"outputId":"4ea20339-3072-4544-dc34-cceaf1c61212"},"cell_type":"code","source":["test_x_180-test_x_135"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]],\n","\n","\n","       [[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]],\n","\n","\n","       [[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]],\n","\n","\n","       ..., \n","       [[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]],\n","\n","\n","       [[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]],\n","\n","\n","       [[[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        ..., \n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         ..., \n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.],\n","         [ 0.,  0.,  0.]]]])"]},"metadata":{"tags":[]},"execution_count":78}]}]}